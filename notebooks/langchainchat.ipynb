{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandasai approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo-1106\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "\n",
    "pre_match_template = \"\"\"\\ \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_completition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(pre_match_template)\n",
    "\n",
    "text = \"top players from brazil that are ready for premier league\"\n",
    "customer_messages = prompt_template.format_messages(text=text)\n",
    "response = chat(customer_messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"top players from brazil that are ready for premier league\"\n",
    "customer_messages = prompt_template.format_messages(text=text)\n",
    "response = chat(customer_messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/ENG1_GPT2_clean.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../data/raw/ENG1_GPT2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Python lists based on the revised categorization\n",
    "\n",
    "# 1. Player Identification and Demographics\n",
    "player_identification_demographics = ['player', 'Position', 'Name', 'Team', 'League', 'Season', 'Age', 'Height', \n",
    "                                      'Weight', 'Birthdate', 'tabb']\n",
    "\n",
    "# 2. Playing Time and Performance Metrics\n",
    "playing_time_performance_metrics = ['Minutes', 'avgawayplaytime', 'avghomeplaytime', 'homeoxg95min', 'awayoxg95min', \n",
    "                                    'homexga95', 'awayxga95', 'homexcs95', 'awayxcs95', 'xGFAR', 'xGAAR', 'xGDAR', \n",
    "                                    'goal', 'goalpershot', 'xgpershot', 'pctxgpass', 'pctxgrecv', 'smgpi', 'smspi', \n",
    "                                    'stxgpi']\n",
    "\n",
    "# 3. Attacking Skills and Style Ratings\n",
    "attacking_skills_style_ratings = ['Attack', 'Forward', 'Carry', 'Receive', 'Shoot', 'Set', 'Dribble', 'Attack_SC', \n",
    "                                  'Attack_BP', 'Attack_OP_SC', 'Attack_OP_BP', 'Attack_DB_SC', 'Attack_DB_BP', \n",
    "                                  'xG_Receive_BP', 'xG_Pass_BP', 'xG_Indv_BP', 'xG_Indv_Takeon_BP', 'xG_Cntr_SC', \n",
    "                                  'xG_Cross_SC', 'xG_Shots', 'xG_Open_SC', 'xG_Dead_SC', 'xG_Open_BP', 'xG_Dead_BP']\n",
    "\n",
    "# 4. Defensive Skills and Style Ratings\n",
    "defensive_skills_style_ratings = ['DefQual', 'DefQuant', 'BallRet', 'Disrupt', 'Recover', 'Aerial', 'Tackle', \n",
    "                                  'xG_Indv_Tackle_BP', 'xG_Indv_Inter_BP', 'xG_Indv_Aerial_BP']\n",
    "\n",
    "# 5. Play Style and Specialties\n",
    "play_style_specialties = ['Link', 'Pass1', 'Pass2', 'Pass3', 'Cross', 'Open_Foot', 'Open_Head', 'Dead_Foot', \n",
    "                          'Dead_Head', 'Direct', 'xG_Indv_Carry_BP', 'xG_Indv_Loose_BP']\n",
    "\n",
    "# 6. Age-Related Traits and Trends\n",
    "age_related_traits_trends = ['a_Hot', 'a_Cold', 'a_Breakout', 'a_Underused', 'a_Prospect']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>Position</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Season</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Birthdate</th>\n",
       "      <th>...</th>\n",
       "      <th>xG_Pass_BP</th>\n",
       "      <th>xG_Indv_BP</th>\n",
       "      <th>xG_Indv_Takeon_BP</th>\n",
       "      <th>xG_Cntr_SC</th>\n",
       "      <th>xG_Cross_SC</th>\n",
       "      <th>xG_Shots</th>\n",
       "      <th>xG_Open_SC</th>\n",
       "      <th>xG_Dead_SC</th>\n",
       "      <th>xG_Open_BP</th>\n",
       "      <th>xG_Dead_BP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>RB</td>\n",
       "      <td>Aleksandr Anyukov</td>\n",
       "      <td>Krylja Sovetov Samara</td>\n",
       "      <td>RUS1</td>\n",
       "      <td>2020</td>\n",
       "      <td>41.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1982.09.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686385</td>\n",
       "      <td>0.365904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660716</td>\n",
       "      <td>0.025375</td>\n",
       "      <td>0.383885</td>\n",
       "      <td>0.585314</td>\n",
       "      <td>0.075403</td>\n",
       "      <td>0.995388</td>\n",
       "      <td>0.451713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>RB</td>\n",
       "      <td>Aleksandr Anyukov</td>\n",
       "      <td>Zenit St Petersburg</td>\n",
       "      <td>RUS1</td>\n",
       "      <td>2017</td>\n",
       "      <td>41.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1982.09.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528842</td>\n",
       "      <td>0.099087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470983</td>\n",
       "      <td>0.069358</td>\n",
       "      <td>0.319344</td>\n",
       "      <td>0.468566</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.643304</td>\n",
       "      <td>0.022921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>RCB</td>\n",
       "      <td>Aleksandr Anyukov</td>\n",
       "      <td>Zenit St Petersburg</td>\n",
       "      <td>RUS1</td>\n",
       "      <td>2019</td>\n",
       "      <td>41.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1982.09.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128599</td>\n",
       "      <td>0.027085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036218</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>0.027564</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>0.126433</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>LB</td>\n",
       "      <td>Aleksandr Anyukov</td>\n",
       "      <td>Zenit St Petersburg</td>\n",
       "      <td>UEL</td>\n",
       "      <td>2019</td>\n",
       "      <td>41.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1982.09.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066955</td>\n",
       "      <td>0.016819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048199</td>\n",
       "      <td>0.007974</td>\n",
       "      <td>0.065013</td>\n",
       "      <td>0.018761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>LB</td>\n",
       "      <td>Roland Gigolaev</td>\n",
       "      <td>Akhmat Grozny</td>\n",
       "      <td>RUS1</td>\n",
       "      <td>2020</td>\n",
       "      <td>33.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1990.01.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307024</td>\n",
       "      <td>0.141159</td>\n",
       "      <td>0.013104</td>\n",
       "      <td>0.130045</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.052395</td>\n",
       "      <td>0.117807</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>0.390201</td>\n",
       "      <td>0.049935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187456</th>\n",
       "      <td>1817914.0</td>\n",
       "      <td>LW</td>\n",
       "      <td>Osvaldo Jesus Vazquez Gomez</td>\n",
       "      <td>Guairena</td>\n",
       "      <td>PAR1</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030391</td>\n",
       "      <td>0.084143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270782</td>\n",
       "      <td>0.161615</td>\n",
       "      <td>0.034849</td>\n",
       "      <td>0.124931</td>\n",
       "      <td>0.052996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187457</th>\n",
       "      <td>1818082.0</td>\n",
       "      <td>CM</td>\n",
       "      <td>Daniel Gomez</td>\n",
       "      <td>Oakland Roots</td>\n",
       "      <td>USA2</td>\n",
       "      <td>2023</td>\n",
       "      <td>23.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2000.05.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316702</td>\n",
       "      <td>0.274931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051597</td>\n",
       "      <td>0.367768</td>\n",
       "      <td>0.066131</td>\n",
       "      <td>0.619794</td>\n",
       "      <td>0.097094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187458</th>\n",
       "      <td>1818581.0</td>\n",
       "      <td>LB</td>\n",
       "      <td>Victor Hugo Rojas Ortiz</td>\n",
       "      <td>Sportivo Ameliano</td>\n",
       "      <td>PAR1</td>\n",
       "      <td>2023</td>\n",
       "      <td>19.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2004.04.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166678</td>\n",
       "      <td>0.143870</td>\n",
       "      <td>0.007787</td>\n",
       "      <td>0.061503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318335</td>\n",
       "      <td>0.007787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187459</th>\n",
       "      <td>1818591.0</td>\n",
       "      <td>DM</td>\n",
       "      <td>Nicolas Agustin Sanchez</td>\n",
       "      <td>Gimnasia y Esgrima La Plata</td>\n",
       "      <td>ARG1</td>\n",
       "      <td>2024</td>\n",
       "      <td>19.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2004.07.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060482</td>\n",
       "      <td>0.123059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110835</td>\n",
       "      <td>0.056730</td>\n",
       "      <td>0.008036</td>\n",
       "      <td>0.153019</td>\n",
       "      <td>0.049696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187460</th>\n",
       "      <td>1819814.0</td>\n",
       "      <td>LCB</td>\n",
       "      <td>Malcolm John Matarr Jeng</td>\n",
       "      <td>Sirius</td>\n",
       "      <td>SWE1</td>\n",
       "      <td>2023</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2005.03.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068202</td>\n",
       "      <td>0.024071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096285</td>\n",
       "      <td>0.132374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187461 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           player Position                         Name  \\\n",
       "0             2.0       RB            Aleksandr Anyukov   \n",
       "1             2.0       RB            Aleksandr Anyukov   \n",
       "2             2.0      RCB            Aleksandr Anyukov   \n",
       "3             2.0       LB            Aleksandr Anyukov   \n",
       "4             9.0       LB              Roland Gigolaev   \n",
       "...           ...      ...                          ...   \n",
       "187456  1817914.0       LW  Osvaldo Jesus Vazquez Gomez   \n",
       "187457  1818082.0       CM                 Daniel Gomez   \n",
       "187458  1818581.0       LB      Victor Hugo Rojas Ortiz   \n",
       "187459  1818591.0       DM      Nicolas Agustin Sanchez   \n",
       "187460  1819814.0      LCB     Malcolm John Matarr Jeng   \n",
       "\n",
       "                               Team League  Season   Age  Height  Weight  \\\n",
       "0             Krylja Sovetov Samara   RUS1    2020  41.0   178.0    67.0   \n",
       "1               Zenit St Petersburg   RUS1    2017  41.0   178.0    67.0   \n",
       "2               Zenit St Petersburg   RUS1    2019  41.0   178.0    67.0   \n",
       "3               Zenit St Petersburg    UEL    2019  41.0   178.0    67.0   \n",
       "4                     Akhmat Grozny   RUS1    2020  33.0   176.0    73.0   \n",
       "...                             ...    ...     ...   ...     ...     ...   \n",
       "187456                     Guairena   PAR1    2023   0.0     0.0     0.0   \n",
       "187457                Oakland Roots   USA2    2023  23.0   175.0    70.0   \n",
       "187458            Sportivo Ameliano   PAR1    2023  19.0   177.0    69.0   \n",
       "187459  Gimnasia y Esgrima La Plata   ARG1    2024  19.0   167.0    69.0   \n",
       "187460                       Sirius   SWE1    2023  18.0     0.0     0.0   \n",
       "\n",
       "         Birthdate  ... xG_Pass_BP  xG_Indv_BP  xG_Indv_Takeon_BP  xG_Cntr_SC  \\\n",
       "0       1982.09.28  ...   0.686385    0.365904           0.000000    0.660716   \n",
       "1       1982.09.28  ...   0.528842    0.099087           0.000000    0.470983   \n",
       "2       1982.09.28  ...   0.128599    0.027085           0.000000    0.036218   \n",
       "3       1982.09.28  ...   0.066955    0.016819           0.000000    0.056173   \n",
       "4       1990.01.04  ...   0.307024    0.141159           0.013104    0.130045   \n",
       "...            ...  ...        ...         ...                ...         ...   \n",
       "187456           0  ...   0.030391    0.084143           0.000000    0.196464   \n",
       "187457  2000.05.07  ...   0.316702    0.274931           0.000000    0.433899   \n",
       "187458  2004.04.26  ...   0.166678    0.143870           0.007787    0.061503   \n",
       "187459  2004.07.20  ...   0.060482    0.123059           0.000000    0.064766   \n",
       "187460  2005.03.09  ...   0.068202    0.024071           0.000000    0.100821   \n",
       "\n",
       "        xG_Cross_SC  xG_Shots  xG_Open_SC  xG_Dead_SC  xG_Open_BP  xG_Dead_BP  \n",
       "0          0.025375  0.383885    0.585314    0.075403    0.995388    0.451713  \n",
       "1          0.069358  0.319344    0.468566    0.002417    0.643304    0.022921  \n",
       "2          0.001210  0.015649    0.027564    0.008654    0.126433    0.029250  \n",
       "3          0.000000  0.000000    0.048199    0.007974    0.065013    0.018761  \n",
       "4          0.009179  0.052395    0.117807    0.012238    0.390201    0.049935  \n",
       "...             ...       ...         ...         ...         ...         ...  \n",
       "187456     0.000000  0.270782    0.161615    0.034849    0.124931    0.052996  \n",
       "187457     0.000000  0.051597    0.367768    0.066131    0.619794    0.097094  \n",
       "187458     0.000000  0.000000    0.061503    0.000000    0.318335    0.007787  \n",
       "187459     0.000000  0.110835    0.056730    0.008036    0.153019    0.049696  \n",
       "187460     0.000000  0.000000    0.100821    0.000000    0.096285    0.132374  \n",
       "\n",
       "[187461 rows x 55 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[player_identification_demographics + playing_time_performance_metrics + attacking_skills_style_ratings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a LLM\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm import OpenAI\n",
    "llm = OpenAI(api_token=\"YOUR_API_TOKEN\")\n",
    "\n",
    "df = SmartDataframe(df, config={\"llm\": llm})\n",
    "df.chat('Which are the 5 happiest countries?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo-1106\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.25, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.25)\n",
    "\n",
    "pre_match_template = \"\"\"\\\n",
    "You are a helpfull assistance that translates queries and conversation into variables of my data, this is the structre of the dataset:\n",
    "Variable\t\tDefinition\n",
    "Player\t\t\tplayer ID\n",
    "Position\t\tposition ID\n",
    "Name\t\t\tplayer name\n",
    "Team\t\t\tteam ID\n",
    "League\t\t\tleague number\n",
    "Season\t\t\tseason number\n",
    "Minutes\t\t\tminutes played at position\n",
    "Attack\t\t\t0-99 attacking output rating\n",
    "DefQual\t\t\t0-99 defending quality rating\n",
    "DefQuant\t\t0-99 defending quantity rating\n",
    "BallRet\t\t\t0-99 ball retention rating\n",
    "Disrupt\t\t\t0-99 disrupt style rating\n",
    "Recover\t\t\t0-99 recover style rating\n",
    "Aerial\t\t\t0-99 aerials style rating\n",
    "Link\t\t\t0-99 linking up style rating\n",
    "Forward\t\t\t0-99 passing toward goal style rating\n",
    "Carry\t\t\t0-99 dribbles/carries style rating\n",
    "Receive\t\t\t0-99 receiving in the box style rating\n",
    "Shoot\t\t\t0-99 shooting style rating\n",
    "Set\t\t\t0-99 aerial duels from dead balls rating\n",
    "Dribble\t\t\t0-99 ground duels in possession rating\n",
    "Tackle\t\t\t0-99 ground duels out of possession rating\n",
    "Open_Foot\t\t0-99 non-headers in open play shooting/saving rating\n",
    "Open_Head\t\t0-99 headers in open play shooting/saving rating\n",
    "Dead_Foot\t\t0-99 non-headers from dead balls shooting/saving rating\n",
    "Dead_Head\t\t0-99 headers from dead balls shooting/saving rating\n",
    "Direct\t\t\t0-99 direct free kicks shooting/saving rating\n",
    "Goal\t\t\tgoal flag\n",
    "GoalperShot\t\tnon-penalty goals per shot\n",
    "xGperShot\t\txG per shot\n",
    "pctxgpass\t\tshare of ball progression xG from passing\n",
    "pctgrecv\t\tshare of ball progression xG from receiving\n",
    "smgpi\t\t\tshare of moves ending in non-penalty goals involving player while on the pitch\n",
    "smspi\t\t\tshare of moves ending in shots involving player while on the pitch\n",
    "stxgpi\t\t\tshare of total xG from moves ending in shots involving player while on the pitch\n",
    "avgawayplaytime\t\taverage playing time away\n",
    "avghomeplaytime\t\taverage playing time at home\n",
    "homeoxg95min\t\txG from shots at home per 95 minutes\n",
    "awayxg95min\t\txG from shots away per 95 minutes\n",
    "homexga95\t\thome xG against per 95 minutes\n",
    "awayxga95\t\taway xG against per 95 minutes\n",
    "homexcs95\t\thome expected clean sheets per 95 minutes\n",
    "awayxcs95\t\taway expected clean sheets per 95 minutes\n",
    "Age\t\t\tplayer age\n",
    "Height\t\t\tplayer height\n",
    "Weight\t\t\tplayer weight\n",
    "Birthdate\t\tplayer birthdate\n",
    "tabb\t\t\tteam abbreviation\n",
    "Pass1\t\t\tstyle rating for passes of 0m to 10m\n",
    "Pass2\t\t\tstyle rating for passes of 10m to 20m\n",
    "Pass3\t\t\tstyle rating for passes of 20m or more\n",
    "Cross\t\t\t0-99 crossing style rating\n",
    "a_Hot\t\t\tage-limited hot flag\n",
    "a_Cold\t\t\tage-limited cold flag\n",
    "a_Breakout\t\tage-limited breakout season flag\n",
    "a_Underused\t\tage-limited underused flag\n",
    "a_Prospect\t\tage-limited young prospect flag\n",
    "Attack_SC\t\tattacking output rating from shot creation model only (0-99 scale)\n",
    "Attack_BP\t\tattacking output rating from ball progression model only (0-99 scale)\n",
    "xG_Receive_BP\t\traw xG in ball progression model from receiving\n",
    "xG_Pass_BP\t\traw xG in ball progression model from passing\n",
    "xG_Indv_BP\t\traw xG in ball progression model from individual play\n",
    "xG_Indv_Takenon_BP\traw xG in ball progression model from take-ons\n",
    "xG_Indv_Tackle_BP\traw xG in ball progression model from tackles\n",
    "xG_Indv_Inter_BP\traw xG in ball progression model from interceptions\n",
    "xG_Indv_Aerial_BP\traw xG in ball progression model from aerials\n",
    "xG_Indv_Carry_BP\traw xG in ball progression model from carries\n",
    "xG_Indv_Loose_BP\traw xG in ball progression model from picking up loose balls\n",
    "xG_Cntr_SC\t\traw xG contributions in shot creation model\n",
    "xG_Cross_SC\t\traw xG crosses in shot creation model\n",
    "xG_Shots\t\traw xG of shots taken\n",
    "xG_Open_SC\t\traw xG contributions in shot creation model in open play\n",
    "xG_Dead_SC\t\traw xG contributions in shot creation model from dead balls\n",
    "xG_Open_BP\t\traw xG contributions in ball progression model in open play\n",
    "xG_Dead_BP\t\traw xG contributions in ball progression model from dead balls\n",
    "xGFAR\t\t\txG for above median replacement player at position per 95 minutes\n",
    "xGAAR\t\t\txG against above median replacement player at position per 95 minutes\n",
    "xGDAR\t\t\txG difference above median replacement player at position per 95 minutes\n",
    "Attack_OP_SC\t\t0-99 attacking output rating for shot creation in open play\n",
    "Attack_OP_BP\t\t0-99 attacking output rating for ball progression in open play\n",
    "Attack_DB_SC\t\t0-99 attacking output rating for shot creation from dead balls\n",
    "Attack_DB_BP\t\t0-99 attacking output rating for ball progression from dead balls\n",
    "\n",
    "Each query needs to be translated into features, for instance young playerss needs to be translated into Age < 23.\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(pre_match_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a LLM\n",
    "from pandasai.llm import OpenAI\n",
    "llm = OpenAI(api_token=\"YOUR_API_TOKEN\")\n",
    "\n",
    "df = SmartDataframe(df, config={\"llm\": llm})\n",
    "df.chat('Which are the 5 happiest countries?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import OpenAI\n",
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "\n",
    "filePath = \"../data/raw/ENG1_GPT.csv\"\n",
    "llm=OpenAI(temperature=0, openai_api_key=os.environ['OPENAI_API_KEY'])\n",
    "\n",
    "agent=create_csv_agent(llm, filePath, verbose=True)\n",
    "agent.run(\"what are the best player from brazil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Chat with your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo-1106\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.25, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.25)\n",
    "\n",
    "pre_match_template = \"\"\"\\\n",
    "Act as a professional analyst in football in which your job is to read, understand and compare metrics and statistics of teams, correlate metrics with tactis \\\n",
    "indentify strengths and weaknesses of teams based on statistics and metrics and propose pontetial plans to succeed in the match with the already known outcomes.\n",
    "Articulate in a professional and appealing manner the analysis of the match and the teams involved, translate complex data into actionable insights and \\\n",
    "recommendations for the team to succeed in the match. At the end think in terms of probability about what's the most likely outcome of the game\n",
    "\n",
    "Be concise and right into the conclusion of the analysis, do not put an introduction, just go to the conclusion.\n",
    "\n",
    "Data of both teams: {text}\n",
    "\"\"\" \n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(pre_match_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Function to send questions to GPT for conversion into structured queries\n",
    "def generate_data_query(question):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant skilled in converting natural language questions into specific data queries using available dataset columns.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.strip()\n",
    "\n",
    "# Function to filter dataset based on the structured query\n",
    "def filter_dataset(structured_query, data):\n",
    "    # Assuming the structured query is a dictionary-like string\n",
    "    query_params = eval(structured_query)\n",
    "\n",
    "    # Apply filters based on query parameters\n",
    "    for key, value in query_params.items():\n",
    "        if key in data.columns:\n",
    "            data = data.query(f\"{key} == {value}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# Main function to process the entire flow\n",
    "def process_question(question, dataset_path):\n",
    "    structured_query = generate_data_query(question)\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    filtered_data = filter_dataset(structured_query, data)\n",
    "    return filtered_data\n",
    "\n",
    "# Example usage\n",
    "question = \"Find young attacking players in the Brazilian league with high shooting stats.\"\n",
    "dataset_path = '../data/raw/ENG1_GPT2.csv'\n",
    "result = process_question(question, dataset_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pypdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each page is a Document.\n",
    "\n",
    "A Document contains text (page_content) and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pages)\n",
    "page = pages[0]\n",
    "print(page.page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install yt_dlp\n",
    "# ! pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "save_dir=\"docs/youtube/\"\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url],save_dir),\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://github.com/basecamp/handbook/blob/master/37signals-is-you.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive splitting details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we load and split our data from several sources\n",
    "\n",
    "Ideas:\n",
    "- Theorethical body for the chatbot using football approaches\n",
    "- Kaggle expert chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.dot(embedding1, embedding2)\n",
    "np.dot(embedding1, embedding3)\n",
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this idea to identify the teams and create a link between them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install chromadb\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./docs/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is there an email i can ask for help\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].page_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
